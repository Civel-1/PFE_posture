{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_IDs = {}\n",
    "with open(\"data/dataset.json\", \"r\") as file:\n",
    "    list_IDs = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTUSequence(Sequence):\n",
    "    \n",
    "    def __init__(self, list_IDs, path, batch_size=32, max_frame=1, one_hot=True):\n",
    "        self.x = list_IDs\n",
    "        self.y = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.max_frame = max_frame\n",
    "        self.path = path\n",
    "        if one_hot:\n",
    "            self.one_hot_encode()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = np.array([self.y[ID] for ID in batch_x])\n",
    "        \n",
    "        X = [np.load(self.path + ID + '.npy')[:, :, :, np.newaxis] for ID in batch_x]\n",
    "        \n",
    "        if not(self.max_frame is None):\n",
    "            X = np.stack(\n",
    "                [x[:max_frame] if x.shape[0] >= max_frame else np.pad(x, ((0, max_frame-x.shape[0]),(0,0),(0,0),(0,0)), \"constant\") for x in X]\n",
    "            )     \n",
    "        \n",
    "        return X, batch_y\n",
    "\n",
    "    def one_hot_encode(self):\n",
    "        labels = [val for val in self.y.values()]\n",
    "        ids = [key for key in self.y.keys()]\n",
    "        labels = to_categorical(labels)\n",
    "        self.y = {ID: label for ID, label in zip(ids, labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-61aa5a158a12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNTUSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_IDs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"D:/PFE/train/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtestset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNTUSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_IDs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"validation\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"D:/PFE/test/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'labels'"
     ]
    }
   ],
   "source": [
    "trainset = NTUSequence(list_IDs[\"train\"], path=\"D:/PFE/train/\")\n",
    "testset = NTUSequence(list_IDs[\"validation\"], path=\"D:/PFE/test/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = models.Sequential([\n",
    "    \n",
    "    layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\", input_shape=(25, 25, 1)),\n",
    "    layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "                        \n",
    "    layers.Conv2D(512, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(512, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Flatten()\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = models.Sequential([\n",
    "    layers.Input((None, 25, 25, 1)),\n",
    "    layers.TimeDistributed(convnet),\n",
    "    \n",
    "    layers.LSTM(9, activation=\"relu\"),\n",
    "    layers.Reshape((3,3,1))\n",
    "    \n",
    "    layers.Conv2DTranspose(1, 3, strides=2, activation=\"relu\", padding=\"same\")\n",
    "    layers.Conv2DTranspose(1, 3, strides=2, activation=\"relu\", padding=\"same\")\n",
    "    layers.Conv2DTranspose(1, 3, strides=2, activation=\"relu\")\n",
    "    \n",
    "    layers.Reshape((25,25))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
