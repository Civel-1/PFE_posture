{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime \n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "min_frame = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_IDs = {}\n",
    "with open(\"data/dataset.json\", \"r\") as file:\n",
    "    list_IDs = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTUSequence(Sequence):\n",
    "    \n",
    "    def __init__(self, list_IDs, path, batch_size=32, one_hot=True, min_frame=min_frame):\n",
    "        # Removed unused vars (self.x, max_frame)\n",
    "        self.x = list_IDs\n",
    "        self.batch_size = batch_size\n",
    "        self.path = path\n",
    "        self.min_frame = min_frame\n",
    "        if one_hot:\n",
    "            self.one_hot_encode()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # idx: index of the data\n",
    "    \n",
    "        # Should be the same as normal\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        \n",
    "        #list of batch_x files \n",
    "        F = [np.load(self.path + ID + '.npy')[:, :, :, np.newaxis] for ID in batch_x]\n",
    "        \n",
    "        if not(self.min_frame is None):\n",
    "            X, Y = [], []\n",
    "            \n",
    "            for x in F:\n",
    "                \n",
    "                if min_frame >= x.shape[0] - 1:\n",
    "                    X.append(min_frame * x[0])\n",
    "                    Y.append(x[0])\n",
    "                    \n",
    "                else:\n",
    "                    f0 = random.randint(min_frame, x.shape[0] - 1)\n",
    "\n",
    "                    X.append(x[f0 - min_frame : f0])\n",
    "                    Y.append(x[f0])\n",
    "\n",
    "                \n",
    "            X = np.stack(X)\n",
    "            Y = np.stack(Y)\n",
    "#         print(\"X=\")\n",
    "#         print(X.shape)\n",
    "#         print(\"Y=\")\n",
    "#         print(Y.shape)\n",
    "        \n",
    "        return X, Y\n",
    "\n",
    "    def one_hot_encode(self):\n",
    "#         labels = [val for val in self.y.values()]\n",
    "#         ids = [key for key in self.y.keys()]\n",
    "#         labels = to_categorical(labels)\n",
    "#         self.y = {ID: label for ID, label in zip(ids, labels)}\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = NTUSequence(list_IDs[\"train\"], path=\"D:/PFE/train/\")\n",
    "testset = NTUSequence(list_IDs[\"validation\"], path=\"D:/PFE/test/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = models.Sequential([\n",
    "    \n",
    "    layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\", input_shape=(25, 25, 1)),\n",
    "    layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "                        \n",
    "    layers.Conv2D(512, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2D(512, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Flatten()\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 25, 25, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 3, 3, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 4,721,152\n",
      "Trainable params: 4,721,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = models.Sequential([\n",
    "    layers.Input((None, 25, 25, 1)),\n",
    "    layers.TimeDistributed(convnet),\n",
    "    \n",
    "    layers.LSTM(9, activation=\"relu\"),\n",
    "    layers.Reshape((3,3,1)),\n",
    "    \n",
    "    layers.Conv2DTranspose(1, 3, strides=2, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2DTranspose(1, 3, strides=2, activation=\"relu\", padding=\"same\"),\n",
    "    layers.Conv2DTranspose(1, 3, strides=2, activation=\"sigmoid\"),\n",
    "    \n",
    "    layers.Reshape((25,25))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, None, 512)         4721152   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 9)                 18792     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 3, 3, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 6, 6, 1)           10        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 12, 12, 1)         10        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 25, 25, 1)         10        \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 25, 25)            0         \n",
      "=================================================================\n",
      "Total params: 4,739,974\n",
      "Trainable params: 4,739,974\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "predictor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.compile(loss=\"mean_squared_logarithmic_error\", optimizer=\"adam\", metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EntraÃ®nement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs\\predictor\\fit\\20200128-195450\n",
      " 623/1157 [===============>..............] - ETA: 14:58 - loss: 0.0324 - mse: 0.0617"
     ]
    }
   ],
   "source": [
    "log_dir=\"logs\\\\predictor\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "print(log_dir)\n",
    "\n",
    "history = predictor.fit_generator(trainset, \n",
    "                     epochs=1,\n",
    "                   callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
