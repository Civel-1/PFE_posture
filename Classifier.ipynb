{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel\n",
    "\n",
    "https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_IDs = {}\n",
    "with open(\"data/dataset.json\", \"r\") as file:\n",
    "    list_IDs = json.load(file)\n",
    "labels = {}\n",
    "with open(\"data/labels.json\", \"r\") as file:\n",
    "    labels = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_config = {\n",
    "    \"batch_size\": 32,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 4,\n",
    "    \"pin_memory\": True,\n",
    "    \"drop_last\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTUDataset(data.Dataset):\n",
    "    def __init__(self, list_IDs, labels, path, max_frame=60):\n",
    "            self.max_frame = max_frame\n",
    "            self.path = path\n",
    "            self.labels = labels\n",
    "            self.list_IDs = list_IDs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "        array = np.load(self.path + ID + '.npy')\n",
    "        if not(self.max_frame is None):\n",
    "            mid_frame = array.shape[0] // 2\n",
    "            array = array[mid_frame-self.max_frame//2:mid_frame+self.max_frame//2]\n",
    "        # Load data and get label\n",
    "        X = torch.from_numpy(array)\n",
    "        y = self.labels[ID]\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "trainset = NTUDataset(list_IDs[\"train\"], labels, path=\"data/processed/train/\")\n",
    "testset = NTUDataset(list_IDs[\"validation\"], labels, path=\"data/processed/test/\")\n",
    "\n",
    "train_gen = data.DataLoader(trainset, **dataloader_config)\n",
    "test_gen = data.DataLoader(testset, **dataloader_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SpatialClassifier, self).__init__()\n",
    "        self.conv11 = nn.Conv3d()\n",
    "        self.conv12 = nn.Conv3d()\n",
    "        \n",
    "        self.conv21 = nn.Conv3d()\n",
    "        self.conv22 = nn.Conv3d()\n",
    "        \n",
    "        self.conv31 = nn.Conv3d()\n",
    "        self.conv32 = nn.Conv3d()\n",
    "        \n",
    "        self.fc = nn.Linear()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv22(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
